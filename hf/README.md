# [ğŸ¤—Huggingface] How to train or inference in CLI?
 - [AutoModel](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModel) with [SequenceClassifierOutput](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1455fFTdWik8K4HhcUbr6t098mzPJ-VSe?usp=share_link) [![wandb](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai/wako/FB_TWO/groups/hf_automodel_cli_pr-Baseline/workspace?workspace=user-wako)
 - [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1c3SLFFqISXPF45HStryBOc1XB_NHd1k8?usp=share_link) [![wandb](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai/wako/FB_TWO/groups/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_cli-Baseline/workspace?workspace=user-wako)
 
     <img src="/imgs/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2023-03-14 á„‹á…©á„’á…® 10.17.29.png" width="83%"></img>


## Check Jupyter Notebook Version
- [AutoModel](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModel) with [SequenceClassifierOutput](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/output#transformers.modeling_outputs.SequenceClassifierOutput) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14HjKUnMtbEUPf-9hSV876jSvUi3xQU3S?usp=share_link) [![wandb](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai/wako/FB_TWO/groups/HuggingFace_Rough_AutoModel-Baseline/workspace?workspace=user-wako)
- [AutoModelForSequenceClassification](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1q-k_I3uBHzT9v1z8TuqfyRpAFGs9XpSW?usp=share_link) [![wandb](https://raw.githubusercontent.com/wandb/assets/main/wandb-github-badge-gradient.svg)](https://wandb.ai/wako/FB_TWO/groups/HuggingFace_Rough_AutoMFSC-Baseline/workspace?workspace=user-wako)
 

     <img src="/imgs/á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2023-03-14 á„‹á…©á„’á…® 10.20.54.png" width="83%"></img>

## Download Data Kaggle API Command 
```python
$ kaggle competitions download -c feedback-prize-effectiveness
$ unzip '*.zip'
```
 
## [wandb login in CLI interface](https://docs.wandb.ai/ref/cli/wandb-login)
```python
$ wandb login --relogin '######### your API token ###########'                  
``` 



## Train 
```bash
$ python train.py --base_path '/content/Kaggle_FB2/huggingface/' \
                  --model_save '/content/drive/MyDrive/ ... /Kaggle FB2/hf/cli2/' \
                  --sub_path '/content/drive/MyDrive/ ... /Kaggle FB2/hf/cli2' \
                  --model "microsoft/deberta-v3-base" \
                  --model_type "AutoModel" \
                  --hash "hf_automodel_cli_practice" \
                  --grad_clipping True\
                  --n_folds 3 \
                  --n_epochs 3 \
                  --device 'cuda' \
                  --max_length 256 \
                  --train_bs 8 \
                  --valid_bs 16
```
- `base_path` : Dataê°€ ì €ì¥ëœ ê²½ë¡œ (Default: `./data/`)
- `sub_path`  : `submission.csv` ì œì¶œí•˜ëŠ” ê²½ë¡œ
- `model_save`: í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë˜ëŠ” ê²½ë¡œ
- `model`: Huggingface Pratrained Model (Default: `"microsoft/deberta-v3-base"`)
- `model_type`: [`AutoModel`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModel) or [`AutoModelForSequenceClassification`](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForSequenceClassification)
- `hash`: Name for WANDB Monitoring
- `n_folds`  : Fold ìˆ˜
- `n_epochs` : Epoch
- `seed` : Random Seed (Default: 2022)
- `train_bs` : Batch Size (Default: 16)
- `max_length` : Max Length (Default: 128) for HuggingFace Tokenizer
- `grad_clipping`: [Gradient Clipping](https://neptune.ai/blog/understanding-gradient-clipping-and-how-it-can-fix-exploding-gradients-problem)
- `ratio` : ë°ì´í„°ë¥¼ Splití•˜ì—¬ `train`(í•™ìŠµ) ê³¼ `valid`(ì„±ëŠ¥ í‰ê°€)ë¥¼ ë§Œë“œëŠ” ë¹„ìœ¨ì„ ì˜ë¯¸. ì •í™•íˆëŠ” `train`ì˜ Size ê²°ì •
- `device`: GPUë¥¼ í†µí•œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤ë©´, `cuda` ë¡œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.
- `learning_rate`, `weight_decay`, `min_lr`, `T_max` ë“±ì€ ìƒëµ 
- [`train.py`](https://github.com/renslightsaber/Kaggle_FB2/blob/main/huggingface/train.py) ì°¸ê³ !   


## ì£¼ì˜
 - CLI í™˜ê²½ì—ì„œ train ì‹œí‚¬ ë•Œ, `tqdm`ì˜ Progress Barê°€ ì—„ì²­ ë§ì´ ìƒì„±ëœë‹¤. ì•„ì§ ì›ì¸ê³¼ í•´ê²°ì„ ëª» ì°¾ì€ ìƒíƒœì´ë‹¤.
 - Colabê³¼ Jupyter Notebookì—ì„œëŠ” ì •ìƒì ìœ¼ë¡œ Progress Barê°€ ë‚˜íƒ€ë‚œë‹¤.



## Inference 
```python

$ python inference.py --base_path './data/' \
                      --model_save '/content/drive/MyDrive/ .. /Kaggle FB2/hf/cli2/' \
                      --sub_path '/content/drive/MyDrive/ ... /Kaggle FB2/hf/cli2/' \
                      --model "microsoft/deberta-v3-base" \
                      --model_type "AutoModel" \
                      --hash "hf_automodel_cli_practici" \
                      --n_folds 3 \
                      --n_epochs 3 \
                      --device 'cuda' \
                      --max_length 256 \
                      --valid_bs 16

```
- `base_path` : Dataê°€ ì €ì¥ëœ ê²½ë¡œ (Default: `./data/`)
- `sub_path`  : `submission.csv` ì œì¶œí•˜ëŠ” ê²½ë¡œ
- `model_save`: í•™ìŠµëœ ëª¨ë¸ì´ ì €ì¥ë˜ëŠ” ê²½ë¡œ
- `model`: trainí–ˆì„ ë•Œì˜ Huggingface Pratrained Model (Default: `"microsoft/deberta-v3-base"`)
- `n_folds`  : `train.py`ì—ì„œ ì§„í–‰í•­ KFold ìˆ˜
- `n_epochs` : train í–ˆì„ ë•Œì˜ Epoch ìˆ˜ (submission íŒŒì¼ëª…ì— ì‚¬ìš©)  
- `seed` : Random Seed (Default: 2022)
- `valid_bs` : Batch Size for Inference (Default: 16) 
- `max_length` : Max Length (Default: 256) for HuggingFace Tokenizer
- `device`: GPUë¥¼ í†µí•œ í•™ìŠµì´ ê°€ëŠ¥í•˜ë‹¤ë©´, `cuda` ë¡œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.
- [`inference.py`](https://github.com/renslightsaber/Kaggle_FB2/blob/main/huggingface/inference.py) ì°¸ê³ !   






